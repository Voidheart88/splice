# Netzwerkmodus Benchmark-Dokumentation

## Ãœbersicht

Diese Dokumentation beschreibt die implementierten Benchmarks fÃ¼r den Netzwerkmodus von Splice, die in `benches/network.rs` zu finden sind.

## Benchmark-Kategorien

### 1. MessagePack Serialisierungs-Benchmarks

**Zweck**: Messung der Serialisierungsgeschwindigkeit fÃ¼r verschiedene SchaltungsgrÃ¶ÃŸen

**Abgedeckte Szenarien**:
- Kleine Schaltungen (3 Elemente: R, C, V)
- Mittlere Schaltungen (10-100 Elemente in Serie)
- GroÃŸe Schaltungen (5x5 bis 10x10 Widerstandsgitter)

**Metriken**:
- Serialisierungszeit pro Schaltung
- AusgabepuffergrÃ¶ÃŸe (Payload-GrÃ¶ÃŸe)
- Skalierungsverhalten mit SchaltungsgrÃ¶ÃŸe

### 2. MessagePack Deserialisierungs-Benchmarks

**Zweck**: Messung der Deserialisierungsgeschwindigkeit fÃ¼r verschiedene SchaltungsgrÃ¶ÃŸen

**Abgedeckte Szenarien**:
- Kleine Schaltungen (3 Elemente)
- Mittlere Schaltungen (50 Elemente)
- GroÃŸe Schaltungen (10x10 Gitter)

**Metriken**:
- Deserialisierungszeit pro Schaltung
- Durchsatz (Schaltungen pro Sekunde)

### 3. Roundtrip-Benchmarks

**Zweck**: Messung der kombinierten Serialisierungs-/Deserialisierungsleistung

**Abgedeckte Szenarien**:
- Kleine, mittlere und groÃŸe Schaltungen
- VollstÃ¤ndiger Zyklus: Objekt â†’ Bytes â†’ Objekt

**Metriken**:
- Gesamtzeit fÃ¼r Roundtrip
- Effektiver Durchsatz

### 4. Simulationstyp-Benchmarks

**Zweck**: Vergleich der Serialisierungsperformance fÃ¼r verschiedene Simulationstypen

**Abgedeckte Simulationstypen**:
- **OP (Arbeitspunktanalyse)**: Einfache Struktur
- **DC (DC-Sweep)**: Parameter fÃ¼r Spannungssweep
- **AC (AC-Analyse)**: Frequenzbereichsdefinition
- **Tran (Transientenanalyse)**: Zeitschritt- und Endzeitparameter

**Metriken**:
- Relative Serialisierungszeit
- Payload-GrÃ¶ÃŸenvergleich

### 5. Ergebnis-Serialisierungs-Benchmarks

**Zweck**: Messung der Serialisierungsperformance fÃ¼r Simulationsergebnisse

**Abgedeckte ErgebnisgrÃ¶ÃŸen**:
- Kleine Ergebnisse (1 Variable)
- Mittlere Ergebnisse (50 Variablen)
- GroÃŸe Ergebnisse (100x50 DC-Sweep-Ergebnisse)

**Metriken**:
- Serialisierungszeit fÃ¼r Ergebnisse
- Speichereffizienz

### 6. Payload-Skalierungs-Benchmarks

**Zweck**: Analyse des Skalierungsverhaltens mit zunehmender SchaltungsgrÃ¶ÃŸe

**Abgedeckte GrÃ¶ÃŸen**:
- 10, 50, 100, 200, 500 Elemente
- Separate Messung von Serialisierung und Deserialisierung

**Metriken**:
- ZeitkomplexitÃ¤t (O(n) Analyse)
- Speicherbedarfsskalierung

## Testschaltungen

### 1. Einfache RC-Schaltung
```
V1 (0 â†’ n1): 5V
R1 (n1 â†’ 0): 1kÎ©
C1 (n1 â†’ 0): 1ÂµF
```

### 2. Mittlere Serien-Schaltung
```
V1 (0 â†’ n1): 5V
R1 (n1 â†’ n2): 1kÎ©
R2 (n2 â†’ n3): 1kÎ©
...
Rn (nX â†’ nX+1): 1kÎ©
C1 (nX+1 â†’ 0): 1ÂµF
```

### 3. GroÃŸes Widerstandsgitter
```
V1 (0 â†’ n1): 5V
Horizontal: R_0_0 (n1 â†’ n2), R_0_1 (n2 â†’ n3), ...
Vertical: Rvert_0 (n1 â†’ nX), Rvert_1 (n2 â†’ nX+1), ...
```

## Benchmark-Ergebnis-Interpretation

### Erwartete Ergebnisse

1. **Serialisierungsperformance**:
   - Lineare Skalierung mit SchaltungsgrÃ¶ÃŸe
   - MessagePack sollte 50-70% kleiner sein als JSON
   - Serialisierung sollte <1ms fÃ¼r kleine, <10ms fÃ¼r mittlere, <100ms fÃ¼r groÃŸe Schaltungen

2. **Deserialisierungsperformance**:
   - Etwas langsamer als Serialisierung (typisch 1.2-1.5x)
   - Sollte Ã¤hnlich skalieren wie Serialisierung

3. **Simulationstyp-Vergleich**:
   - OP: Schnellste (einfache Struktur)
   - DC: Mittlere KomplexitÃ¤t
   - AC/Tran: Komplexeste (mehr Parameter)

### Performance-Ziele

| SchaltungsgrÃ¶ÃŸe | Serialisierung | Deserialisierung | Roundtrip |
|----------------|----------------|------------------|-----------|
| Klein (3 Elemente) | < 100Âµs | < 150Âµs | < 250Âµs |
| Mittel (50 Elemente) | < 1ms | < 1.5ms | < 2.5ms |
| GroÃŸ (100+ Elemente) | < 10ms | < 15ms | < 25ms |

## Benchmark-AusfÃ¼hrung

### Einzelne Benchmark-Gruppe ausfÃ¼hren
```bash
cargo bench -- network_benches
```

### Spezifischen Benchmark ausfÃ¼hren
```bash
cargo bench -- bench_msgpack_serialization
```

### Alle Benchmarks ausfÃ¼hren
```bash
cargo bench
```

## Performance-OptimierungsmÃ¶glichkeiten

### 1. Serialisierungsoptimierungen
- **Buffer-Wiederverwendung**: Pool von Byte-Buffern
- **Inkrementelle Serialisierung**: Streaming fÃ¼r groÃŸe Schaltungen
- **Kompression**: Optional fÃ¼r sehr groÃŸe Schaltungen

### 2. Deserialisierungsoptimierungen
- **Direkte Deserialisierung**: In vorhandene Strukturen
- **Parallelisierung**: FÃ¼r sehr groÃŸe Ergebnisse
- **Lazy Deserialisierung**: On-demand-Laden von Daten

### 3. Protokolloptimierungen
- **BinÃ¤re Optimierung**: Custom Binary Format statt MessagePack
- **Delta-Kodierung**: FÃ¼r Ã¤hnliche Schaltungen
- **Schema-Evolution**: Versionierung fÃ¼r zukÃ¼nftige KompatibilitÃ¤t

## Vergleich mit Alternativen

### MessagePack vs JSON
- **GrÃ¶ÃŸe**: MessagePack ist 50-70% kleiner
- **Geschwindigkeit**: MessagePack ist 2-5x schneller
- **Typensicherheit**: MessagePack behÃ¤lt Typinformationen

### MessagePack vs Protocol Buffers
- **FlexibilitÃ¤t**: MessagePack ist schemalos
- **Einfachheit**: MessagePack hat geringeren Overhead
- **Performance**: Vergleichbar fÃ¼r kleine bis mittlere Payloads

### MessagePack vs Custom Binary
- **Entwicklungsgeschwindigkeit**: MessagePack ist einfacher zu implementieren
- **Wartbarkeit**: MessagePack hat bessere Tool-UnterstÃ¼tzung
- **Performance**: Custom Binary kÃ¶nnte 10-30% schneller sein

## ZukunftsplÃ¤ne fÃ¼r Benchmarks

### Kurzfristig (1-2 Wochen)
- [x] Grundlegende Serialisierungs-Benchmarks
- [x] Deserialisierungs-Benchmarks
- [x] Roundtrip-Benchmarks
- [x] Skalierungsanalysen

### Mittelfristig (1 Monat)
- [ ] Netzwerk-Latenz-Benchmarks (TCP-Overhead)
- [ ] Gleichzeitige Verbindungen (Stress-Tests)
- [ ] Langlauf-Benchmarks (StabilitÃ¤t)

### Langfristig (3+ Monate)
- [ ] Vergleich mit anderen SPICE-Implementierungen
- [ ] Cloud-Skalierungs-Benchmarks
- [ ] Geografische Latenz-Tests

## Best Practices fÃ¼r Netzwerk-Benchmarking

### 1. Konsistente Testumgebung
- Gleiche Hardware fÃ¼r alle Tests
- Keine anderen laufenden Prozesse
- Netzwerkisolation fÃ¼r Latenztests

### 2. Statistische Signifikanz
- Mehrere DurchlÃ¤ufe pro Test
- Warm-up-Phase vor Messung
- AusreiÃŸer-Eliminierung

### 3. Realistische Szenarien
- Echte Schaltungsdaten verwenden
- Variierende Netzwerkbedingungen simulieren
- FehlerfÃ¤lle testen

### 4. Dokumentation
- Klare Benchmark-Beschreibungen
- Versionskontrolle der Testdaten
- Reproduzierbare Ergebnisse

## Fehlerbehandlung in Benchmarks

### HÃ¤ufige Probleme
1. **Timeouts**: Bei sehr groÃŸen Schaltungen
2. **Speicherlimit**: Bei extrem groÃŸen Gitter-Schaltungen
3. **Netzwerkprobleme**: Bei TCP-Benchmarks

### LÃ¶sungsstrategien
- **Chunking**: GroÃŸe Schaltungen in Teile aufteilen
- **Streaming**: Inkrementelle Verarbeitung
- **Timeouts**: Angemessene Limits setzen

## Zusammenfassung

Die implementierten Netzwerk-Benchmarks bieten eine umfassende Abdeckung der kritischen Performance-Aspekte:

âœ… **Serialisierung/Deserialisierung**: Grundlegende MessagePack-Performance
âœ… **Skalierung**: Verhalten mit zunehmender SchaltungsgrÃ¶ÃŸe
âœ… **Simulationstypen**: Unterschiedliche KomplexitÃ¤tsstufen
âœ… **Ergebnisverarbeitung**: Output-Serialisierung

ğŸš§ **Geplant**: Netzwerk-Latenz, Gleichzeitigkeit, LangzeitstabilitÃ¤t

Diese Benchmarks ermÃ¶glichen:
- Performance-Regessionstests
- Optimierungsvalidierung
- KapazitÃ¤tsplanung fÃ¼r Produktionsumgebungen
- Vergleich mit alternativen Implementierungen
